{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa07235",
   "metadata": {},
   "source": [
    "# Using OpenAi Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e65f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fafb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']  = os.getenv('OPEN_ROUTER_API_KEY')\n",
    "os.environ['OPENAI_API_BASE'] = \"https://openrouter.ai/api/v1\"\n",
    "os.environ[\"OPENAI_MODEL_NAME\"] = \"openai/gpt-4.1-mini\"      # openai/gpt-oss-20b:free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ee48390",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1905c03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "who is Leo Messi?\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdaeece9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lionel Messi, commonly known as Leo Messi, is an Argentine professional footballer who plays as a forward for Paris Saint-German and the Argentina national team. Widely regarded as one of the greatest football players of all time, Messi has won numerous awards and accolades throughout his career, including seven Ballon d'Or titles. He is renowned for his incredible dribbling ability, precise finishing, and vision on the field.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354e3f8e",
   "metadata": {},
   "source": [
    "## Calculate Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e1b1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mango/miniconda3/envs/ai_env/lib/python3.9/site-packages/langchain_openai/chat_models/base.py:401: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Why couldn't the bicycle stand up by itself?\\n\\nBecause it was two-tired!\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "prompt_1 = \"\"\"\n",
    "who is Mo Salah?\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt_2 = \"\"\"\n",
    "tell me a joke\n",
    "\"\"\".strip()\n",
    "\n",
    "messages_1 = [HumanMessage(content=prompt_1)]\n",
    "messages_2 = [HumanMessage(content=prompt_2)]\n",
    "\n",
    "llm_results = llm.generate(messages = [messages_1, messages_2])\n",
    "llm_results.generations[1][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46783480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 73,\n",
       "  'prompt_tokens': 23,\n",
       "  'total_tokens': 96,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': None,\n",
       "   'audio_tokens': None,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': None},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_results.llm_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7715db",
   "metadata": {},
   "source": [
    "# Using HuggingFace Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2620325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, Llama4ForCausalLM, LlamaTokenizer, GenerationConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dd3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model_id = \"ibm-granite/granite-4.0-h-micro\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit = True, device_map = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a155d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model,\n",
    "    tokenizer=tokenizer,\n",
    "    # max_new_tokens=10,\n",
    "    max_lenght = 256\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63161c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "Suggest 3 ways to lose my weight to be fit.\n",
    "\n",
    "Answer:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c036e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
